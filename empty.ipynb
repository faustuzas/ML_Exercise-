{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TKO_3120 Machine Learning and Pattern Recognition\n",
    "\n",
    "Image recognition exercise\n",
    "\n",
    "Sam Student <br>\n",
    "sam.student@utu.fi\n",
    "\n",
    "January 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is the template for the image recognition exercise. <Br>\n",
    "Some **general instructions**:\n",
    " - write a clear *report*, understandable for an unspecialized reader: define shortly the concepts and explain the phases you use\n",
    "    - use the Markdown feature of the notebook for larger explanations\n",
    " - return your output as a working Jupyter notebook\n",
    " - name your file as MLPR20_exercise_surname.jpynb\n",
    " - write easily readable code with comments     \n",
    "     - if you exploit some code from web, provide a reference\n",
    "     - avoid redundant code! Exploit the relevent parts and modify the code for your purposes to produce only what you need \n",
    " - it is ok to discuss with a friend about the assignment. But it is not ok to copy someone's work. Everyone should submit their own implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deadline 13th of March at 16:00**\n",
    "- No extension granted, unless you have an extremely justified reason. In such case, ask for extension well in advance!\n",
    "- Start now, do not leave it to the last minute. This exercise will need some labour!\n",
    "- If you encounter problems, Google first and if you canâ€™t find an answer, ask for help\n",
    "    - pekavir@utu.fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grading**\n",
    "\n",
    "The exercise covers a part of the grading in this course. The course exam has 5 questions, 6 points of each. Exercise gives 4 points, i.e. the total score is 34 points. Two extra points can be acquired by completing the bonus task. <br>\n",
    "\n",
    "From the template below, you can see how many exercise points can be acquired from each task. Exam points are given according to the table below: <br>\n",
    "<br>\n",
    "7-8 exercise points: 1 point <br>\n",
    "9-10 exercise points: 2 points <br>\n",
    "11-12 exercise points: 3 points <br>\n",
    "13-14 exercise points: 4 points <br>\n",
    "<br>\n",
    "To pass the exercise, you need at least 7 exercise points, distributed somewhat evenly into tasks (you can't just implement Introduction, Data preparation and Feature extraction and leave the left undone!) <Br>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an introductory chapter for your report **(1 p)**\n",
    "<br>E.g.\n",
    "- What is the purpose of this task?\n",
    "- What kind of data were used? Where did it originate?\n",
    "- Which methods did you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images: https://unsplash.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform preparations for the data **(3 p)**\n",
    "- import all the packages needed for this notebook in one cell\n",
    "- read the URL:s from the text files and import the images\n",
    "- crop and/or resize the images into same size\n",
    "- for GLCM and GLRLM, change the images into grayscale and reduce the quantization level, e.g. to 8 levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First order texture measures (6 features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the below mentioned color features for each image **(1 p)**\n",
    "    - Mean for each RGB color channel\n",
    "    - Variance for each RGB color channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second order texture measures (4 or 10 features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gray-Level-Co-Occurrence (GLCM) features (4 features) **(2 p)**\n",
    "    - For each image\n",
    "        - calculate the GLC matrix\n",
    "        - calculate the \"correlation\" feature using the GLC matrix that you acquired \n",
    "            - in horizontal and vertical directions for two reference pixel distances (you can choose the distances)\n",
    "        - explain your choise for the distances<br>\n",
    "<br>\n",
    "- Gray-Level-Run-Length (GLRL) features (6 features) **(BONUS)**\n",
    "    - Make an own implementation for Gray-Level-Run-Length (GLRL) matrix in\n",
    "        - horizontal direction\n",
    "        - vertical direction\n",
    "        - test that your code works with the toy image: [[1,1,1,0],[2,0,0,1],[1,0,2,2],[0,0,0,0]]\n",
    "    - Implement the following run-length features using the GLRL matrix that you acquired\n",
    "        - Short-Run emphasis\n",
    "        - Long-run emphasis\n",
    "        - Run percentage\n",
    "    - Include the resulting features in the input array X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather your features into an input array X, and the image classes into an output array y. Standardize the feature values in X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make illustrations of the feature relationships, and discuss the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot\n",
    "\n",
    "- Pairplot **(1 p)**\n",
    "    - Which feature pairs possess roughly linear dependence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PCA **(1 p)**\n",
    "    - Can you see any clusters in PCA?\n",
    "    - Does this figure give you any clues, how well you will be able to classify the image types? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build classifiers and estimate their performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- k Nearest Neighbors classifier **(1 p)**\n",
    "    - optimize the hyperparameter (k) and select the best model for the classifier\n",
    "    - estimate the performance of the model with nested cross validation\n",
    "    - calculate the accuracy and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularized linear model with Ridge regression **(1 p)**\n",
    "    - optimize the hyperparameter (alpha) and select the best model for the classifier\n",
    "    - estimate the performance of the model with nested cross validation\n",
    "    - calculate the accuracy and the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Multi-layer perceptron MLP **(2 p)**\n",
    "    - build the classifier. Use:\n",
    "        - 1 hidden layer\n",
    "        - solver for weight optimization: stochastic gradient-based optimizer ('adam')\n",
    "        - activation function for the hidden layer: rectified linear unit function ('relu')\n",
    "        - Early stop\n",
    "    - optimize the number of neurons in the hidden layer and select the best model for the classifier\n",
    "    - use Early stop committee, i.e. after selecting the model, calculate the prediction for the test data several times with different sampling of the training data. The members of the committee vote for the predicted class of the test sample. Use 50% of the training data for validation (algorithm terminates the training when validation score is not improving)\n",
    "    - estimate the performance of the classifier with nested cross validation\n",
    "    - calculate the accuracy and the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discuss you results **(1 p)**\n",
    "<br>E.g.\n",
    "    - Which model performs the best and why?\n",
    "    - What are the limitations?\n",
    "    - How could the results be improved?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
