{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TKO_3120 Machine Learning and Pattern Recognition\n",
    "\n",
    "### Image recognition exercise\n",
    "\n",
    "Faustas Butkus\n",
    "faustas.f.butkus@utu.fi\n",
    "\n",
    "March 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores basic techniques of image preprocessing, data exploration, machine learning classification algorithms and comparison between them.\n",
    "\n",
    "Three types of images are used for the input data: _sand, grass_ and _stairs_.\n",
    "Links to those images are stored in separate files. <br>\n",
    "All images are provided by https://unsplash.com/.\n",
    "\n",
    "Classification algorithms used:\n",
    "* K-Nearest Neighbours\n",
    "* Ridge regression\n",
    "* Multilayer perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used throughout whole project\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image category will be represented as an integer because machine learning algorithms require that all data are provided as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers associated with category and the filename where urls are stored\n",
    "image_categories = [\n",
    "    (0, 'sand.txt'), \n",
    "    (1, 'grass.txt'), \n",
    "    (2, 'stairs.txt')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation & features extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RGB image is stored as a matrix of pixels where each of it consists of three integers (ranging from 0 to 255) which are representations of red, green and blue colour intensities.\n",
    "\n",
    "There are numerous ways and options to extract simple and complex features from the image. The features that are going to be used in this project are very basic ones and might not fully reflect the image, but they are quickly and easily extractable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features concerning the colours\n",
    "\n",
    "* *Mean value of each colour channel in the image* shows how much certain colour is intensive over the all image. E.g. Image of the grass should have a high intensity of green.\n",
    "* *Variance of each colour channel in the image* describes how much ranges the intensity of colour over the image. E.g. Stairs often have different lighting on them therefore the top stair will have a different shade of grey than the bottom one.\n",
    "\n",
    "#### Features conserning the texture\n",
    "\n",
    "To explore the texture of the image **Gray-Level-Co-Occurrence matrix (GLCM)** technique is used. It is defined by calculating the occurrence of pixel values at a given offset. Certain attributes, like *correlation*, can be calculated from the matrix. It can be defined at different angles allowing to know the texture in any direction.\n",
    "\n",
    "* 0° and 90° correlations will be calculated with offsets of 3 and 10 px to gather the knowledge of how fast the texture changes in very small and slighly bigger distances in vertical and horizontal directions. E.g. Sand should be way smoother that stairs in vertical direction.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "\n",
    "def resize_img(img, shape):\n",
    "    \"\"\"Resize image to provided shape\"\"\"\n",
    "    return transform.resize(img, shape, preserve_range=True)\n",
    "\n",
    "def preprocess_img(img):\n",
    "    \"\"\"Prepare image for feature extraction\"\"\"\n",
    "    \n",
    "    # Resize image to uniform shape for more convenient feature extraction\n",
    "    resized_image = resize_img(img, (300, 300))\n",
    "    \n",
    "    return resized_image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_channel_mean(img, channel_index):\n",
    "    \"\"\"Calculate colour channel mean over all image\"\"\"\n",
    "    channel = img[:, :, channel_index]\n",
    "    return np.mean(channel)\n",
    "\n",
    "def img_r_mean(img):\n",
    "    return img_channel_mean(img, 0)\n",
    "\n",
    "def img_g_mean(img):\n",
    "    return img_channel_mean(img, 1)\n",
    "\n",
    "def img_b_mean(img):\n",
    "    return img_channel_mean(img, 2)\n",
    "\n",
    "def img_channel_variance(img, channel_index):\n",
    "    \"\"\"Calculate colour channel variance over all image\"\"\"\n",
    "    channel = img[:, :, channel_index]\n",
    "    return np.var(channel)\n",
    "\n",
    "def img_r_variance(img):\n",
    "    return img_channel_variance(img, 0)\n",
    "\n",
    "def img_g_variance(img):\n",
    "    return img_channel_variance(img, 1)\n",
    "\n",
    "def img_b_variance(img):\n",
    "    return img_channel_variance(img, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage.feature import texture\n",
    "\n",
    "def glcm_correlation(img, pixel_distances, angles=[0, np.pi / 2], levels=8):\n",
    "    \"\"\"\n",
    "    Calculates the GLCM and correlation using the matrix.\n",
    "    \n",
    "        Parameters:\n",
    "            img: image to calculate correlation for\n",
    "            pixel_distances: array of offsets to calculate the distribution over\n",
    "            angles: angles in radians for which to calculate matrix\n",
    "            levels: quantization level of the image. Lower is faster but less precise.\n",
    "            \n",
    "        Returns:\n",
    "            correlations: numpy array made of correlations for each pixel distance\n",
    "    \"\"\"\n",
    "    \n",
    "    # GLCM requires that the image is grayscaled\n",
    "    grayscaled = color.rgb2gray(img).astype(int)\n",
    "    \n",
    "    # Reduce the quantization level of the image\n",
    "    reduced = np.floor((grayscaled / 255) * levels).astype(int)\n",
    "    \n",
    "    # Calculate the GLCM for the image\n",
    "    glcms = texture.greycomatrix(\n",
    "        image=reduced, \n",
    "        distances=pixel_distances, \n",
    "        angles=angles, \n",
    "        levels=levels, \n",
    "        normed=True, \n",
    "        symmetric=True\n",
    "    )\n",
    "    \n",
    "    # Calculate correlation of pixel values from the matrix\n",
    "    correlations = texture.greycoprops(glcms, 'correlation')\n",
    "    \n",
    "    # Return result as a numpy array\n",
    "    return np.array([correlations[:, i] for i, _ in enumerate(pixel_distances)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img):\n",
    "    \"\"\"Extract features from the image and build a vector from them\"\"\"\n",
    "    \n",
    "    # Calculate the correlations for the image\n",
    "    correlations = glcm_correlation(img, [3, 10])\n",
    "    \n",
    "    # Extract horizontal and vertical correlations into separate features\n",
    "    horizontal_smoothness = correlations[:, 0]\n",
    "    vertical_smoothness = correlations[:, 1]\n",
    "    \n",
    "    # Compose the feature vector of the image\n",
    "    return (\n",
    "        img_r_mean(img),\n",
    "        img_g_mean(img),\n",
    "        img_b_mean(img),\n",
    "        img_r_variance(img),\n",
    "        img_g_variance(img),\n",
    "        img_b_variance(img),\n",
    "        *horizontal_smoothness,\n",
    "        *vertical_smoothness\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from all the images and create data set from them\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "input_array = []\n",
    "\n",
    "# Iterate through available categories\n",
    "for cid, filename in image_categories:\n",
    "    \n",
    "    # Load urls from the file\n",
    "    urls = np.loadtxt(filename, dtype='U150')\n",
    "    \n",
    "    for url in urls:\n",
    "        # Download the image and extract features from it\n",
    "        img = io.imread(url)\n",
    "        preprocessed_img = preprocess_img(img)\n",
    "        features = extract_features(preprocessed)\n",
    "        \n",
    "        # Append images features to input vector alongside associated category\n",
    "        input_array.append(\n",
    "            [*features, cid]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
